# Demand Forecasting System
Автоматизированная MLOps-система для ежедневного прогнозирования спроса в розничной сети (на примере данных Rossmann). Проект реализует полный жизненный цикл модели: от приёма сырых данных до визуализации прогнозов и мониторинга производственных запусков.

---
## Оглавление
- [Обзор проекта](#Обзор-проекта)
- [Архитектура системы](#Архитектура-системы)
- [Технологический стек](#Технологический-стек)
- [Структура проекта](#Структура-проекта)
- [Установка и настройка](#Установка-и-настройка)
- [Запуск системы](#Запуск-системы)
- [Работа с данными](#Работа-с-данными)
- [Мониторинг и логирование](#Мониторинг-и-логирование)
- Результаты и производительность
- Ограничения
- Дальнейшее развитие


---
## Обзор проекта
**Demand Forecasting System** - готовое к производственной эксплуатации решение для прогнозирования ежедневных продаж в масштабах розничной сети. Система автоматизирует:
- сбор и очистку исторических данных о продажах и характеристиках магазинов;
- инжиниринг признаков (временные, лаговые, промо, праздничные, конкурентные);
- обучение и оптимизацию градиентного бустинга (LightGBM) с помощью Optuna;
- оркестрацию ежедневных и еженедельных задач через Apache Airflow;
- хранение истории продаж, прогнозов, метрик и логов запусков в реляционной БД (SQLite);
- визуализацию результатов в интерактивном дашборде на Dash/Plotly;
- мониторинг состояния пайплайна, алерты при сбоях.

Целевая точность прогноза **- MAPE < 10**%. Текущая версия достигает **9.7%** на тестовой выборке.

---
## Архитектура системы
Система построена на принципах **MLOps** и модульности. Основные компоненты:
1. **Источники данных** - CSV-файлы с продажами (```train.csv```, ```test.csv```) и справочник магазинов (```store.csv```).
2. **Модуль предобработки** - валидация, очистка, объединение, обработка пропусков.
3. **Модуль признаков** - генерация 70+ признаков (лаг, скользящие статистики, циклическое кодирование, One-Hot, бизнес-флаги).
4. **Менеджер истории** - агрегация продаж, расчёт лаговых признаков на лету, кэширование в SQLite.
5. **Модель** - LightGBM с автоматическим подбором гиперпараметров (Optuna, TimeSeriesSplit, pruning).
6. **ETL-пайплайн** - извлечение, трансформация, прогноз, загрузка результатов.
7. **Оркестратор** - Apache Airflow, два DAG: ```demand_forecasting_pipeline``` (daily) и ```weekly_model_retraining``` (weekly).
8. **Мониторинг DAG** - сбор статистики запусков, success rate, алерты.
9. **База данных** - SQLite (таблицы: ```sales_history```, ```predictions```, ```pipeline_runs```, ```model_metrics```)
10. **Визуализация** – Dash-приложение с фильтрацией по магазинам и датам, графиками, метриками, таблицей прогнозов.

---
## Технологический стек
| Категория | Технологии |
| --------------- | --------------- |
| **Язык** | Python 3.13+ |
| **Оркестрация** | Apache Airflow 3.x |
| **ML-фреймворк** | LightGBM, scikit-learn, Optuna |
| **Обработка данных**	 | Pandas, NumPy, joblib |
| **База данных**	 | SQLite, sqlite3 |
| **Визуализация**	 | Dash, Plotly, Matplotlib, Seaborn |
| **Тестирование**	 | pytest, unittest |
| **Окружение**	 | Windows WSL2 (для Airflow), Linux, Python venv |

---
## Структура проекта
```
demand_forecasting/
├── airflow/
│   └── dags/
│       ├── demand_forecasting_dag.py          # Основной DAG
│       └── monitoring/
│           └── dag_monitor.py                 # Мониторинг DAG
├── config/
│   └── settings.py                           # Настройки путей
├── data/
│   ├── raw/                                  # Сырые данные
│   ├── processed/                            # Очищенные данные, признаки, история
│   └── outputs/                              # Прогнозы (predictions.csv)
├── models/
│   └── lgbm_final_model.pkl                 # Обученная модель LightGBM
├── notebooks/                               # EDA и сравнение моделей
├── reports/                                 # Графики, отчёты
├── scripts/
│   ├── setup_wsl.py                        # Настройка WSL окружения
│   └── run_airflow.py                      # Запуск Airflow в WSL
├── src/
│   ├── data/                               # Предобработка, качество данных, история
│   ├── database/                           # DatabaseManager, DashboardDataProvider, миграция
│   ├── features/                           # Feature engineering
│   ├── models/                             # BaseModels, BaselineModels, LGBMModel
│   ├── pipeline/                           # ETLPipeline, PipelineOperations
│   └── visualization/                      # Dash-дашборд, компоненты, assets
├── tests/                                  # Юнит- и интеграционные тесты
├── requirements.txt                        # Зависимости Python
└── README.md                              # Документация (этот файл)
```

---
# Установка и настройка
1. **Клонирование репозитория**
```
git clone https://github.com/your-org/demand_forecasting.git
cd demand_forecasting
```

2. **Создание виртуального окружения и установка зависимостей**
Linux / macOS / WSL:
```
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```
Windows (без WSL):
```
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
```
**Примечание**: Airflow требует окружения **Unix-подобной ОС**. На Windows рекомендуется использовать **WSL2** (см. раздел ниже).

3. **Настройка WSL (только для Windows)**
Если вы работаете на Windows и планируете запускать Airflow, выполните:
```python scripts/setup_wsl.py```

Скрипт автоматически:
- проверит наличие WSL2;
- создаст виртуальное окружение внутри WSL;
- установит все зависимости из ```requirements.txt```.

4. **Инициализация базы данных**
При первом запуске система автоматически создаёт SQLite‑файл ```demand_forecasting.db``` в каталоге ```data/```.
Для миграции существующих данных из ```sales_history.pkl``` и ```predictions.csv``` выполните:
```python -m src.database.migrate_to_db```

---
# Запуск системы
1. **Запуск Airflow (оркестратор)**
Вариант А - через WSL (рекомендуется на Windows):
```python scripts/run_airflow.py```

Скрипт:
- синхронизирует DAG‑файлы и исходный код в WSL;
- инициализирует/очищает БД Airflow;
- запускает **API‑сервер** (```http://localhost:8080```) и **scheduler**.
- автоматически выполняет ресериализацию DAG.

Вариант Б - напрямую в Linux / WSL:
```
export AIRFLOW_HOME=~/demand_forecasting/airflow
airflow db migrate
airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com
airflow api-server --port 8080 -D
airflow scheduler -D
```

2. **Запуск дашборда**
```python src/visualization/dashboard.py```
Дашборд будет доступен по адресу ```http://localhost:8050```.

3. **Ручной запуск DAG (опционально)**
```airflow dags trigger demand_forecasting_pipeline```

---
# Работа с данными

## Источники
- **train.csv** - исторические продажи за 2013-2015 гг. (около 786 тыс. записей).
- **store.csv** - статическая информация о 1115 магазинах.
- **test.csv** - данные для формирования прогнозов (используется в ETL-пайплайне).
---
## Этапы обработки
1. **Загрузка и объединение** - ```DataPreprocessor.load_and_merge_data```.
2. **Очистка** - фильтрация закрытых магазинов (```Open == 1```), продажи > 0, обработка пропусков, удаление дубликатов.
3. **Инжиниринг признаков** - ```FeatureEngineer```:
  - временные (Year, Month, Week, DayOfWeek_sin/cos, IsWeekend, IsMonthStart);
  - промо‑признаки (PromoSequence, DaysSinceLastPromo, IsPromoStart/End);
  - праздничные (IsHoliday, WasHolidayYesterday, IsChristmas, IsEaster);
  - магазинные (One‑Hot encoding StoreType, Assortment);
  - конкурентные (CompetitionOpenMonths, CompetitionNear/Far);
  - лаговые (SalesLag_1,7,14,28; RollingMean/Std/Min/Max) - рассчитываются через ```SalesHistoryManager``` на основе всей доступной истории.
4. **Формирование финального датасета** - исключение служебных колонок, сохранение в ```final_dataset.csv```.

---
## Обучение модели
- **Baseline**: LinearRegression, RandomForest, MeanBaseline.
- **Основная модель**: LightGBM с оптимизацией гиперпараметров (Optuna, 100 trials, TimeSeriesSplit, MedianPruner).
- **Метрики**: MAPE, RMSE, MAE, R², RMSPE, MedAE, Bias.
- **Автоматическое сохранение**: модель (```lgbm_final_model.pkl```), метрики, важность признаков, параметры.

---
## Прогнозирование
- ETL-пайплайн загружает предобученную модель, применяет все трансформации к ```test.csv``` и сохраняет результаты в ```outputs/predictions.csv``` и в таблицу ```predictions``` БД.

---
# Мониторинг и логирование

## Мониторинг DAG
Модуль ```DAGMonitor```:
- логирует каждый запуск DAG (статус, количество выполненных задач, ошибки);
- рассчитывает **success rate**;
- хранит историю последних 50 запусков;
- генерирует алерты при:
  - двух последовательных неудачах;
  - success rate < 80%;
- формирует отчёт о производительности (```reports/performance_report.json```).

---
## Логирование в БД
```DatabaseManager``` автоматически сохраняет:
- **Запуски пайплайна** - run_id, DAG, статус, время, метрики, ошибки.
- **Метрики модели** - при каждом обучении фиксируется версия, MAPE, RMSE, параметры.
- **Прогнозы** - привязка к run_id, возможность сравнения двух запусков.

---
# Результаты и производительность
| Модель | MAPE (%) | R² | 	MAE (€) | RMSE (€) | Время обучения |
| --------------- | --------------- | --------------- |
| **LightGBM** | 9.70 | 0.915 | 652.5 | 932.7 | ~15 мин |
| **RandomForest** | 9.79 | 0.907 | 665.5 | 980.1 | 212 с |
| **LinearRegression** | 12.69 | 0.848 | 849.3 | 1248.7 | 2 с |
| **MeanBaseline**	 | 36.28 | -0.019 | 2326.1 | 3237.8 | 0.02 с |
Включая 100 итераций Optuna (на полном наборе данных ~700 тыс. строк).
**Тестовый период**: последние 30% временной шкалы (все магазины).
